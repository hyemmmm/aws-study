# AWS 스토리지 서비스 가이드

## 1. Amazon S3 (Simple Storage Service)

### 1.1 S3란 무엇인가

Amazon S3는 인터넷을 통해 접근 가능한 객체 스토리지 서비스다. '객체 스토리지'라는 개념이 핵심인데, 이는 파일 시스템이나 블록 스토리지와 근본적으로 다른 방식으로 데이터를 저장한다.

**파일 시스템 vs 객체 스토리지**

일반적인 파일 시스템(예: 윈도우 탐색기)은 디렉토리 트리 구조로 파일을 계층적으로 관리한다. 반면 객체 스토리지는 평면(flat) 구조다. 모든 객체가 같은 레벨에 존재하며, `folder/subfolder/file.txt` 같은 경로는 실제 폴더가 아니라 단순히 객체의 키(key) 이름일 뿐이다.

| 구분 | 파일 시스템 | 객체 스토리지 |
|------|------------|--------------|
| 구조 | 계층적 트리 구조 | 평면 구조 (키-값) |
| 메타데이터 | 제한적 (이름, 크기, 날짜) | 무제한 커스텀 메타데이터 |
| 수정 방식 | 일부 수정 가능 | 전체 교체만 가능 |
| 접근 방식 | 파일 경로 | HTTP URL |
| 확장성 | 단일 서버 한계 | 무제한 확장 |

**객체(Object)의 구성**

S3에 저장되는 각 객체는 세 가지 요소로 구성된다:
- 키(Key): 객체의 고유 식별자. 버킷 내에서 유일해야 한다.
- 값(Value): 실제 데이터. 최대 50TB까지 저장 가능.
- 메타데이터: 객체에 대한 추가 정보. 시스템 메타데이터(Content-Type 등)와 사용자 정의 메타데이터로 구분.

**S3의 특징**

- 용량 무제한 (객체 당은 50TB의 제한)
- 이론 상 99.999999999%의 내구성 (3개 이상의 AZ로 복사)
- 저렴한 비용

**S3 객체 당 50TB의 제한의 역사와 구조적 배경**

S3의 객체 크기 제한은 시간이 지나면서 발전해왔다:

| 시기 | 최대 객체 크기 | 주요 변화 |
|------|---------------|----------|
| 초기 S3 | 5GB | 단일 PUT 요청으로 업로드 |
| 2010년 이후 | 5TB | 멀티파트 업로드 API 도입 |
| 2025년 12월 | 50TB | 대규모 AI/ML 데이터셋 수요 대응 |

50TB 제한이 존재하는 구조적 이유는 멀티파트 업로드의 기술적 제약과 관련이 있다:
- 최대 파트 수: 10,000개
- 파트당 최대 크기: 5GB
- 이론적 최대 = 10,000 × 5GB = 50TB

실제로 이 제한은 대부분의 사용 사례에서 충분하며, AWS는 내부적으로 데이터를 청크 단위로 분산 저장하고 관리하기 때문에 무한정 큰 단일 객체를 허용하면 복구, 복제, 일관성 검증 등의 운영 복잡성이 기하급수적으로 증가한다.


### 1.2 S3의 내부 동작 원리

**데이터 분산 저장**

S3에 객체를 업로드하면, AWS는 해당 데이터를 자동으로 최소 3개의 가용 영역(AZ)에 분산 저장한다. 각 AZ는 물리적으로 분리된 데이터센터이므로, 하나의 데이터센터가 완전히 파괴되어도 데이터는 안전하다. 이것이 S3가 99.999999999%(11 nines) 내구성을 제공하는 방식이다.


**결과적 일관성에서 강력한 일관성으로**

과거 S3는 '결과적 일관성(eventual consistency)' 모델을 사용했다. 객체를 업로드하거나 삭제한 직후 조회하면 이전 버전이 보일 수 있었다. 2020년 12월부터 S3는 모든 작업에 대해 '강력한 일관성(strong consistency)'을 제공한다. PUT 또는 DELETE 직후 GET 요청은 항상 최신 상태를 반환한다.

https://www.allthingsdistributed.com/2021/04/s3-strong-consistency.html

**멀티파트 업로드**

100MB 이상의 대용량 파일은 멀티파트 업로드를 권장한다. 

동작 방식:
- 파일을 여러 파트(최소 5MB)로 분할
- 각 파트를 병렬로 업로드
- 모든 파트 업로드 완료 후 S3가 자동으로 조립
- 실패한 파트만 재전송 가능 (전체 재시작 불필요)


### 1.3 버킷(Bucket)과 객체 관리

**버킷의 특성**

버킷은 객체를 담는 컨테이너다. 중요한 특성들:
- 버킷 이름은 전 세계적으로 고유해야 한다 (모든 AWS 계정 통틀어)
- 버킷은 특정 리전에 생성되며, 객체는 명시적으로 복제하지 않는 한 해당 리전을 벗어나지 않는다
- 한 계정당 기본 100개 버킷 제한 (요청 시 증가 가능)
- 버킷 내 객체 수는 무제한 (객체 당은 50TB)

**버전 관리(Versioning)**

버전 관리를 활성화하면 같은 키로 객체를 덮어써도 이전 버전이 보존된다. 각 버전은 고유한 버전 ID를 가진다. 삭제 요청 시에도 실제로 삭제되지 않고 '삭제 마커(delete marker)'가 추가된다. 이전 버전 복원이 필요하면 해당 버전 ID를 지정해 조회하면 된다.


**수명 주기(Lifecycle) 정책**

객체의 생애 주기를 자동화할 수 있다:
- 전환(Transition): 일정 기간 후 더 저렴한 스토리지 클래스로 자동 이동
- 만료(Expiration): 일정 기간 후 객체 자동 삭제
- 버전 정리: 이전 버전이나 불완전한 멀티파트 업로드 정리

### 1.4 스토리지 클래스와 비용 최적화

S3는 접근 빈도와 검색 시간 요구사항에 따라 여러 스토리지 클래스를 제공한다:

| 스토리지 클래스 | 용도 | 검색 시간 | 최소 저장 기간 |
|----------------|------|----------|---------------|
| S3 Standard | 자주 접근하는 데이터 | 즉시 | 없음 |
| S3 Intelligent-Tiering | 접근 패턴 예측 불가 | 즉시 | 없음 |
| S3 Standard-IA | 월 1회 정도 접근 | 즉시 | 30일 |
| S3 One Zone-IA | 재생성 가능한 비자주 접근 데이터 | 즉시 | 30일 |
| S3 Glacier Instant | 분기 1회 접근, 즉시 필요 | 밀리초 | 90일 |
| S3 Glacier Flexible | 연 1-2회 접근 | 분~시간 | 90일 |
| S3 Glacier Deep Archive | 거의 접근 안 함 (규정 준수용) | 12~48시간 | 180일 |


**Intelligent-Tiering의 동작 방식**

접근 패턴을 예측하기 어려울 때 유용하다. 
예를 들어 S3가 각 객체의 접근 패턴을 모니터링하고
- 30일간 접근 없으면 Infrequent Access 티어로 이동
- 90일간 접근 없으면 Archive Instant Access 티어로 이동 (선택적)
- 접근 시 자동으로 Frequent Access 티어로 복귀
- 티어 간 이동에 검색 비용 없음 (모니터링 비용만 발생)

### 1.5 접근 제어와 보안

**버킷 정책(Bucket Policy)**

JSON 형식의 리소스 기반 정책으로, 버킷과 그 안의 객체에 대한 접근을 제어한다. 다른 AWS 계정이나 익명 사용자에게 권한을 부여할 때 주로 사용한다.

**IAM 정책**

IAM 사용자, 그룹, 역할에 연결되는 자격 증명 기반 정책이다. 버킷 정책과 IAM 정책이 동시에 적용되면, 명시적 거부가 항상 우선하고, 그 다음 명시적 허용을 확인하며, 둘 다 없으면 기본 거부된다.

**ACL(Access Control List)**

레거시 방식의 접근 제어다. AWS는 새 버킷에 대해 ACL 비활성화를 권장한다. 버킷 정책이 더 세밀한 제어를 제공하기 때문이다.

**퍼블릭 액세스 차단**

S3에는 4단계의 퍼블릭 액세스 차단 설정이 있다. 계정 레벨과 버킷 레벨 모두에서 설정 가능하며, 실수로 버킷을 공개하는 것을 방지한다. 프로덕션 환경에서는 특별한 이유가 없는 한 모든 퍼블릭 액세스 차단을 활성화해야 한다.

**데이터 암호화**

S3는 두 가지 레벨의 암호화를 제공한다:

**서버 측 암호화(SSE):** 데이터가 S3에 저장될 때 자동으로 암호화된다.
- SSE-S3: AWS가 관리하는 키 사용. 가장 간단.
- SSE-KMS: AWS KMS 키 사용. 키 사용 감사 로그 제공.
- SSE-C: 고객이 제공한 키 사용. 키 관리 책임은 고객.

**클라이언트 측 암호화:** 데이터를 S3로 보내기 전에 클라이언트에서 암호화. 전송 중에도 암호화된 상태 유지.

### 1.6 S3와 다른 서비스 연계

**정적 웹사이트 호스팅**

S3 버킷을 웹 서버처럼 사용할 수 있다. HTML, CSS, JavaScript, 이미지 등 정적 파일을 서빙하는 데 적합하다. 서버 측 스크립트(PHP, Node.js 등)는 실행 불가능하다.

정적 웹사이트란 서버 측 처리 없이 파일 그대로 브라우저에 전달되는 웹사이트다. React, Vue 같은 SPA도 빌드하면 정적 파일(HTML, JS, CSS)이 되므로 S3로 호스팅 가능하다. 단, API 호출은 별도 백엔드(Lambda, EC2 등)가 처리해야 한다.

**S3 정적 웹사이트 호스팅과 HTTPS**

S3 기본 엔드포인트(`https://bucket-name.s3.amazonaws.com`)는 HTTPS를 지원한다. AWS가 `*.s3.amazonaws.com` 와일드카드 인증서로 모든 버킷을 커버하기 때문이다.

반면 S3 정적 웹사이트 엔드포인트(`http://bucket-name.s3-website-region.amazonaws.com`)는 HTTPS를 지원하지 않는다. 기술적으로는 와일드카드 인증서로 커버 가능한 구조지만, AWS가 지원하지 않기로 한 설계 결정이다. 아마도 CloudFront와 함께 사용하도록 유도하려는 의도로 보인다.

실무에서 S3 정적 웹사이트를 직접 노출하는 경우는 거의 없고, CloudFront를 앞에 두어 HTTPS 종단점으로 사용한다. ACM(AWS Certificate Manager)에서 무료 SSL 인증서를 발급받아 CloudFront에 연결하면 된다.

**이벤트 알림**

객체 생성, 삭제 등의 이벤트 발생 시 다른 AWS 서비스를 트리거할 수 있다:
- Lambda: 이미지 업로드 시 자동 썸네일 생성
- SQS: 이벤트를 큐에 넣어 비동기 처리
- SNS: 이메일/SMS 알림 발송
- EventBridge: 복잡한 이벤트 라우팅

**교차 리전 복제(CRR)**

한 리전의 버킷에서 다른 리전의 버킷으로 객체를 자동 복제한다. 재해 복구, 지연 시간 단축, 규정 준수 요구사항 충족에 사용된다. 복제에는 버전 관리 활성화가 필수다.


## 2. Amazon EBS (Elastic Block Store)

### 2.1 EBS란 무엇인가

EBS는 EC2 인스턴스에 연결하는 블록 스토리지다. 물리 서버에 하드 드라이브나 SSD를 장착하는 것과 유사한 개념이다. S3가 HTTP로 접근하는 객체 스토리지라면, EBS는 파일 시스템을 만들어 마운트하는 블록 스토리지다.

**블록 스토리지의 특성**

블록 스토리지는 데이터를 고정 크기의 블록으로 나누어 저장한다:
- 파일의 일부만 수정 가능 (S3는 전체 교체만 가능)
- 운영체제가 파일 시스템(ext4, NTFS 등)을 직접 관리
- 랜덤 I/O에 최적화
- 데이터베이스, 부팅 볼륨 등에 적합


### 2.2 EBS 볼륨 타입

워크로드 특성에 따라 적절한 볼륨 타입을 선택해야 한다:

| 볼륨 타입 | 용도 | 최대 IOPS | 최대 처리량 |
|----------|------|-----------|------------|
| gp3 (범용 SSD) | 대부분의 워크로드 | 16,000 | 1,000 MB/s |
| gp2 (범용 SSD) | 이전 세대 범용 | 16,000 | 250 MB/s |
| io2/io2 Block Express | 고성능 DB | 256,000 | 4,000 MB/s |
| st1 (처리량 최적화 HDD) | 빅데이터, 로그 | 500 | 500 MB/s |
| sc1 (콜드 HDD) | 자주 접근 안 하는 대용량 | 250 | 250 MB/s |



### 2.3 EBS의 내부 동작

**네트워크 연결 스토리지**

EBS 볼륨은 EC2 인스턴스와 같은 물리 서버에 있지 않다. 네트워크를 통해 연결된다. 이 설계의 장점:
- 인스턴스 종료 후에도 데이터 유지
- 볼륨을 다른 인스턴스에 연결 가능
- 스냅샷으로 백업 용이



**단일 AZ 제약**

EBS 볼륨은 특정 가용 영역(AZ)에 존재한다. 해당 AZ의 EC2 인스턴스만 연결할 수 있다. 다른 AZ로 이동하려면 스냅샷을 생성하고 대상 AZ에서 새 볼륨을 생성해야 한다.


### 2.4 스냅샷과 AMI

**스냅샷 동작 방식**

EBS 스냅샷은 S3에 저장되는 증분 백업이다:
- 첫 스냅샷: 전체 볼륨 복사
- 이후 스냅샷: 변경된 블록만 저장
- 스냅샷 삭제 시: 다른 스냅샷에서 참조하지 않는 블록만 삭제
- 복원: 어떤 스냅샷에서든 완전한 볼륨 복원 가능


**AMI와의 관계**

AMI(Amazon Machine Image)는 EC2 인스턴스의 템플릿이다. AMI에는 EBS 스냅샷에 대한 참조가 포함된다. AMI에서 인스턴스를 시작하면 해당 스냅샷에서 루트 볼륨이 생성된다.



## 3. 파일 스토리지 및 기타 서비스

### 3.1 Amazon EFS (Elastic File System)

**EFS vs EBS**

EFS는 여러 EC2 인스턴스가 동시에 접근할 수 있는 공유 파일 시스템이다. EBS는 단일 인스턴스 연결이 기본인 반면, EFS는 수천 개의 인스턴스가 동시에 마운트할 수 있다.

| 특성 | EBS | EFS |
|-----|-----|-----|
| 접근 범위 | 단일 인스턴스 (기본) | 다중 인스턴스 |
| AZ 범위 | 단일 AZ | 리전 전체 (다중 AZ) |
| 프로토콜 | 블록 (직접 연결) | NFS v4.1 |
| 용량 | 미리 프로비저닝 | 자동 확장/축소 |
| 비용 모델 | 프로비저닝 용량 | 실제 사용량 |


**EFS 동작 방식**

EFS는 NFS(Network File System) 프로토콜을 사용한다. 각 AZ에 마운트 타겟을 생성하고, EC2 인스턴스는 해당 마운트 타겟을 통해 파일 시스템에 접근한다. 데이터는 자동으로 다중 AZ에 복제되어 내구성을 보장한다.

**성능 모드**
- 범용(General Purpose): 대부분의 워크로드에 적합. 지연 시간 우선.
- 최대 I/O: 높은 병렬 처리가 필요한 빅데이터 워크로드. 처리량 우선, 지연 시간 약간 높음.

**처리량 모드**
- 버스팅: 저장 용량에 비례한 기본 처리량 + 크레딧 기반 버스트.
- 프로비저닝: 처리량을 명시적으로 지정. 일정한 높은 처리량 필요 시.
- Elastic: 워크로드에 따라 자동 조절. 예측 불가능한 패턴에 적합.

**스토리지 클래스**

EFS도 S3처럼 스토리지 클래스가 있다:
- Standard: 자주 접근하는 데이터
- Infrequent Access (IA): 자주 접근하지 않는 데이터 (최대 92% 저렴)
- 수명 주기 정책으로 자동 전환 가능

### 3.2 Amazon FSx

FSx는 특정 파일 시스템이 필요할 때 사용하는 완전 관리형 서비스다.

**FSx for Windows File Server**

Windows 네이티브 SMB 프로토콜을 지원한다. Active Directory 통합, DFS(Distributed File System), 섀도 복사본 등 Windows 파일 서버 기능을 제공한다. Windows 기반 애플리케이션을 AWS로 마이그레이션할 때 유용하다.

**FSx for Lustre**

Lustre는 HPC(High Performance Computing)에 최적화된 병렬 파일 시스템이다. 머신러닝 훈련, 금융 모델링, 동영상 렌더링 등 대규모 컴퓨팅 워크로드에 적합하다. S3와 네이티브 통합을 제공하여 S3 데이터를 Lustre 파일 시스템으로 자동 로드하고 결과를 다시 S3로 저장할 수 있다.

**FSx for NetApp ONTAP**

NetApp의 ONTAP 파일 시스템을 AWS에서 완전 관리형으로 제공한다. NFS, SMB, iSCSI 프로토콜을 모두 지원한다. 온프레미스 NetApp 환경과의 호환성이 필요할 때 선택한다.

**FSx for OpenZFS**

ZFS 파일 시스템 기반이다. 데이터 중복 제거, 압축, 스냅샷 등 ZFS의 고급 기능을 AWS에서 사용할 수 있다.

### 3.3 AWS Transfer Family

SFTP, FTPS, FTP 프로토콜로 S3나 EFS에 파일을 전송할 수 있게 해주는 서비스다.

**사용 사례**
- 레거시 파일 전송 워크플로우를 클라우드로 마이그레이션
- 파트너사가 기존 FTP 클라이언트를 계속 사용하면서 S3에 직접 업로드
- 기존 인증 시스템(AD, LDAP) 통합

**동작 방식**

Transfer Family 서버를 생성하면 AWS가 프로토콜 엔드포인트를 제공한다. 사용자 인증 후 전송된 파일은 지정된 S3 버킷이나 EFS 파일 시스템에 저장된다. 서버 관리, 스케일링, 패칭은 AWS가 담당한다.

### 3.4 AWS Backup

여러 AWS 서비스의 백업을 중앙에서 관리하는 서비스다.

**지원 서비스**

EBS, EFS, RDS, DynamoDB, Aurora, Storage Gateway, FSx, EC2 등 대부분의 스토리지/데이터베이스 서비스를 지원한다.

**백업 계획(Backup Plan)**

백업 정책을 정의한다:
- 백업 빈도: 매일, 매주, 매월 등
- 백업 윈도우: 백업 실행 시간대
- 수명 주기: 콜드 스토리지로 전환 시점, 삭제 시점
- 교차 리전 복사: DR을 위한 다른 리전 복제


### 3.5 AWS DataSync

온프레미스 스토리지와 AWS 간, 또는 AWS 서비스 간 데이터 이동을 자동화한다.

**vs 일반 복사 도구**

rsync나 일반 복사 도구 대비 장점:
- 자동 암호화 및 데이터 검증
- 네트워크 최적화로 빠른 전송 (최대 10Gbps)
- 대역폭 조절 기능
- 스케줄링 및 모니터링 내장
- 증분 전송 지원


### 3.6 AWS Snow Family

네트워크를 통한 데이터 전송이 비실용적일 때 물리적 디바이스로 데이터를 이동한다.

**디바이스 종류**

| 디바이스 | 스토리지 용량 | 용도 |
|---------|-------------|------|
| Snowcone | 8-14 TB | 엣지 컴퓨팅, 소규모 전송 |
| Snowball Edge Storage | 80 TB | 페타바이트 마이그레이션 |
| Snowball Edge Compute | 42-80 TB | 엣지 컴퓨팅 + 스토리지 |
| Snowmobile | 100 PB | 엑사바이트급 마이그레이션 |

**사용 프로세스**
- 콘솔에서 작업(Job) 생성
- AWS가 디바이스 배송
- 온프레미스에서 데이터 복사
- AWS로 반송
- AWS가 데이터를 S3로 가져오기

**언제 Snow를 사용하나**

경험적으로, 1Gbps 회선으로 1주일 이상 걸리는 데이터(약 60TB 이상)면 Snow를 고려한다. 100Mbps 회선이면 약 6TB부터 Snow가 유리할 수 있다.


## 4. 서비스 선택 가이드

### 4.1 의사결정 흐름

**질문 1: 어떤 접근 방식이 필요한가?**
- HTTP/REST API로 접근 → S3
- 파일 시스템으로 마운트 → EFS, FSx
- 블록 디바이스로 연결 → EBS

**질문 2: 공유가 필요한가?**
- 단일 인스턴스 전용 → EBS
- 여러 인스턴스가 동시 접근 → EFS, FSx
- 애플리케이션/서비스 간 공유 → S3

**질문 3: 어떤 프로토콜이 필요한가?**
- NFS → EFS 또는 FSx for ONTAP
- SMB (Windows) → FSx for Windows
- Lustre (HPC) → FSx for Lustre
- SFTP/FTP → Transfer Family + S3


### 4.2 비용 최적화 체크리스트

- S3: 접근 패턴에 맞는 스토리지 클래스 사용, Intelligent-Tiering 고려
- EBS: 실제 필요한 IOPS/처리량 분석, gp3 우선 검토, 미사용 볼륨 정리
- EFS: IA 스토리지 클래스 활용, 처리량 모드 최적화
- 스냅샷/백업: 보존 정책 설정, 불필요한 스냅샷 정리
- 데이터 전송: 같은 AZ 내 전송 무료, 리전 간 전송 비용 주의
